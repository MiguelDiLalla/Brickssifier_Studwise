"""
LEGO Bricks ML Vision - Training Pipeline

This module provides a complete ML training pipeline for LEGO Bricks and Studs detection
models using YOLOv8. It handles dataset preparation, training configuration, model training
and results management.

Key features:
  - Automatic hardware detection (CUDA/MPS/CPU)
  - Dataset extraction and validation 
  - Train/validation/test dataset splitting
  - Data augmentation via Albumentations
  - Model selection and training
  - Results compression and sharing
  - Detailed logging with emoji markers

Usage examples:
  - Direct API: from train import train_model, setup_logging
  - Through notebooks: See Train_Pipeline.ipynb for interactive usage

Author: Miguel DiLalla
"""

import os
import logging
import torch
import shutil
import zipfile
import json
import random
import datetime
import subprocess
import numpy as np
import cv2
import albumentations as A
from albumentations.pytorch import ToTensorV2
import yaml
import matplotlib.pyplot as plt
from ultralytics import YOLO
from pathlib import Path
from IPython.display import FileLink, display
from pprint import pprint
import pandas as pd

# =============================================================================
# Logging Setup
# =============================================================================

class EmojiFormatter(logging.Formatter):
    """Custom formatter that adds context-aware emoji markers to log messages.
    
    Enhances log readability with ML-specific emojis for different stages:
    - Dataset operations: ðŸ“‚ ðŸ” 
    - Training events: ðŸš€ ðŸ“ˆ
    - Hardware/Setup: ðŸ’» âš™ï¸
    - Results/Evaluation: ðŸ“Š ðŸ“‹
    - Errors/Warnings: âŒ âš ï¸
    """
    def format(self, record):
        base_msg = super().format(record)
        
        # Define emoji mappings based on message content
        dataset_keywords = ['dataset', 'images', 'labels', 'augment']
        training_keywords = ['epoch', 'training', 'model', 'batch']
        hardware_keywords = ['gpu', 'cuda', 'device', 'cpu']
        results_keywords = ['results', 'evaluation', 'metrics']
        
        msg_lower = record.msg.lower()
        
        # Select contextual emoji
        if record.levelno >= logging.ERROR:
            emoji = "âŒ"
        elif record.levelno >= logging.WARNING:
            emoji = "âš ï¸"
        elif any(kw in msg_lower for kw in dataset_keywords):
            emoji = "ðŸ“‚"
        elif any(kw in msg_lower for kw in training_keywords):
            emoji = "ðŸš€"
        elif any(kw in msg_lower for kw in hardware_keywords):
            emoji = "ðŸ’»"
        elif any(kw in msg_lower for kw in results_keywords):
            emoji = "ðŸ“Š"
        else:
            emoji = "âœ…"
            
        return f"{base_msg} {emoji}"

def setup_logging():
    """Configure rich logging with context-aware emojis and color coding.
    
    Features:
        - Emoji indicators for different operation types
        - Color-coded log levels
        - Both console and file output
        - Automatic log directory creation
        
    The logging configuration is global and will be used by all module functions.
    """
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, "train_session.log")
    
    formatter = EmojiFormatter("%(asctime)s - %(levelname)s - %(message)s")
    
    # Console handler with color support
    stream_handler = logging.StreamHandler()
    stream_handler.setFormatter(formatter)
    
    # File handler for persistent logs
    file_handler = logging.FileHandler(log_file, mode="a")
    file_handler.setFormatter(formatter)
    
    # Reset any existing handlers
    logger = logging.getLogger()
    if logger.hasHandlers():
        logger.handlers.clear()
    
    # Configure global logging
    logging.basicConfig(
        level=logging.INFO,
        handlers=[stream_handler, file_handler]
    )
    
    logging.info("ML Training pipeline initialized with enhanced logging")

# =============================================================================
# Environment Setup
# =============================================================================

def get_repo_root() -> Path:
    """
    Auto-detects the repository root directory.
    
    Returns:
        Path: The repository root directory path.
        
    Notes:
        - Searches for .git directory moving up from current location
        - Falls back to current working directory if not found
    """
    current_dir = Path(__file__).resolve().parent
    while current_dir != current_dir.parent:  # Avoid infinite loops
        if (current_dir / ".git").exists():
            return current_dir
        current_dir = current_dir.parent  # Move up one level

    # If no .git found, return the current execution directory
    return Path.cwd()

def detect_hardware():
    """
    Detects available hardware for training.
    
    Returns:
        str: Device specification for PyTorch (e.g., "0,1" for multiple GPUs, "cpu", or "mps")
        
    Notes:
        - Checks for CUDA-capable GPUs and returns all available devices
        - Falls back to Apple MPS if available
        - Defaults to CPU with warning if no accelerators found
    """
    if torch.cuda.is_available():
        num_gpus = torch.cuda.device_count()
        device = ",".join(str(i) for i in range(num_gpus))
        logging.info(f"Detected {num_gpus} GPU(s): {device}")
        return device  # Returning the actual device list like "0,1"
    
    elif torch.backends.mps.is_available():
        logging.info("Detected Apple MPS device.")
        return "mps"
    
    logging.warning("No GPU or MPS device detected. Falling back to CPU.")
    return "cpu"

def setup_execution_structure(repo_root):
    """
    Ensures all necessary cache directories exist before execution.
    
    Creates standardized folder structure for:
      - Cache (datasets, models, logs)
      - Results
      
    Returns:
        None
    """
    
    required_dirs = [
        repo_root / "cache" / "datasets",
        repo_root / "cache" / "models",
        repo_root / "cache" / "logs",
        repo_root / "results"  # âœ… FIXED: Ensuring results go to the right place
    ]
    for directory in required_dirs:
        directory.mkdir(parents=True, exist_ok=True)
    logging.info("âœ… Execution structure initialized.")

def cleanup_training_sessions(repo_root):
    """
    Cleans up temporary directories after training completion.
    
    Removes:
      - cache/
      - results/
      
    Returns:
        None
      
    Notes:
        - Preserves original dataset files
        - Logs successful and failed cleanup operations
    """
    
    folders = ["cache", "results"]
    for folder in folders:
        folder_path = os.path.join(repo_root, folder)
        if os.path.exists(folder_path):
            for root, dirs, files in os.walk(folder_path):
                for file in files:
                    os.remove(os.path.join(root, file))
                for dir in dirs:
                    shutil.rmtree(os.path.join(root, dir))
            logging.info(f"âœ… Emptied: {folder_path}")
        else:
            logging.warning(f"âŒ Not found: {folder_path}. Creating it now.")
            os.makedirs(folder_path, exist_ok=True)
            logging.info(f"âœ… Created: {folder_path}")

def export_logs(log_name="train_session"):
    """
    Exports logs and hardware details in JSON format.
    
    Args:
        log_name (str): Base name for the log file (without extension)
        
    Returns:
        str: Path to the exported JSON file
        
    Notes:
        - Includes hardware details (GPU, CUDA version, etc.)
        - Preserves all log entries in structured format
    """
    log_path = os.path.join("logs", f"{log_name}.log")
    export_path = log_path.replace(".log", ".json")
    
    hardware_info = {
        "python_version": torch.__version__,
        "cuda_available": torch.cuda.is_available(),
        "device_name": torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU",
        "num_gpus": torch.cuda.device_count(),
        "torch_version": torch.__version__,
        "timestamp": datetime.datetime.now().isoformat()
    }
    
    with open(log_path, "r") as f:
        log_entries = [line.strip() for line in f.readlines()]
    
    session_data = {
        "hardware_info": hardware_info,
        "logs": log_entries
    }
    
    with open(export_path, "w") as f:
        json.dump(session_data, f, indent=4)
    
    logging.info(f"âœ… Logs exported to {export_path}")
    return export_path

# =============================================================================
# Dataset Preparation
# =============================================================================

def unzip_dataset(mode, force_extract=False):
    """Extracts and prepares the LEGO detection dataset for training.

    This function handles dataset extraction from compressed archives while implementing
    caching to avoid redundant extractions. Dataset archives should be located in 
    the 'presentation/Datasets_Compress' directory.

    Args:
        mode (str): Detection mode, either 'bricks' or 'studs'.
        force_extract (bool, optional): Force re-extraction even if cache exists.

    Returns:
        str: Path to the extracted dataset root directory.

    Example:
        >>> dataset_path = unzip_dataset('bricks')
        >>> print(f"Dataset extracted to: {dataset_path}")

    Notes:
        - Expects ZIP archives named 'bricks_dataset.zip' or 'studs_dataset.zip'
        - Creates cache/datasets/{mode} directory structure
        - Preserves original compressed archives
    """
    repo_root = get_repo_root()
    dataset_compressed_dir = os.path.join(repo_root, "presentation/Datasets_Compress")
    dataset_dir = os.path.join(repo_root, "cache/datasets")
    
    dataset_filename = "bricks_dataset.zip" if mode == "bricks" else "studs_dataset.zip"
    dataset_path = os.path.join(dataset_compressed_dir, dataset_filename)
    extract_path = os.path.join(dataset_dir, mode)

    os.makedirs(dataset_dir, exist_ok=True)

    if not force_extract and os.path.exists(extract_path):
        logging.info(f"Dataset already extracted at {extract_path}. Skipping extraction.")
        return extract_path

    logging.info(f"Extracting {dataset_filename}...")
    shutil.unpack_archive(dataset_path, extract_path)
    logging.info(f"Dataset extracted to: {extract_path}")

    return extract_path

def validate_dataset(mode):
    """Validates and sanitizes the YOLO format detection dataset.

    Performs comprehensive dataset validation including:
    1. Structure verification (images + labels folders)
    2. Image integrity checks (corrupt file detection)
    3. YOLO annotation format validation  
    4. Image-label pair consistency
    5. Automatic cleanup of invalid files

    Args:
        mode (str): Detection mode, either 'bricks' or 'studs'.

    Returns:
        tuple(str, str): Paths to validated (images_dir, labels_dir).

    Raises:
        ValueError: If dataset structure is invalid or no valid pairs found.

    Example:
        >>> img_dir, lbl_dir = validate_dataset('bricks')
        >>> print(f"Valid pairs found in {img_dir} and {lbl_dir}")

    Notes:
        - Removes corrupt images
        - Removes malformed label files
        - Ensures 1:1 image-label correspondence
        - Provides detailed validation statistics
    """
    logging.info(f"Starting dataset validation for {mode} mode")
    
    # Get paths
    repo_root = get_repo_root()
    dataset_path = os.path.join(repo_root, "cache/datasets", mode)
    
    # Find subfolders
    subfolders = [f for f in os.listdir(dataset_path) 
                  if os.path.isdir(os.path.join(dataset_path, f))]
    
    if len(subfolders) != 2:
        logging.error(f"Expected 2 subfolders, found {len(subfolders)}")
        raise ValueError("Invalid dataset structure")

    # Detect images and labels folders
    images_path = None
    labels_path = None
    
    for folder in subfolders:
        folder_path = os.path.join(dataset_path, folder)
        sample_files = os.listdir(folder_path)[:5]  # Check first 5 files
        
        # Check if folder contains images
        if any(f.lower().endswith(('.jpg', '.jpeg', '.png')) for f in sample_files):
            images_path = folder_path
        # Check if folder contains text files
        elif any(f.lower().endswith('.txt') for f in sample_files):
            labels_path = folder_path
    
    if not images_path or not labels_path:
        logging.error("Could not identify images and labels folders")
        raise ValueError("Invalid dataset structure")
        
    logging.info(f"Detected - Images: {images_path}, Labels: {labels_path}")

    # Validate images
    valid_images = []
    for img in os.listdir(images_path):
        if not img.lower().endswith(('.jpg')):
            continue
            
        img_path = os.path.join(images_path, img)
        try:
            image = cv2.imread(img_path)
            if image is None:
                logging.warning(f"Removing corrupted image: {img}")
                os.remove(img_path)
            else:
                valid_images.append(os.path.splitext(img)[0])
        except Exception as e:
            logging.warning(f"Error processing image {img}: {e}")
            os.remove(img_path)

    # Validate labels
    valid_labels = []
    for label in os.listdir(labels_path):
        if not label.endswith('.txt'):
            continue
            
        label_path = os.path.join(labels_path, label)
        try:
            with open(label_path, 'r') as f:
                lines = f.readlines()
                
            # Check YOLO format: each line should be "class x y w h"
            format_errors = []
            for line_num, line in enumerate(lines, 1):
                if line.strip():  # Skip empty lines
                    try:
                        values = line.split()
                        if len(values) != 5:
                            format_errors.append(f"Line {line_num}: Expected 5 values, got {len(values)}")
                        elif not all(0 <= float(x) <= 1 for x in values[1:]):
                            format_errors.append(f"Line {line_num}: Values must be between 0 and 1")
                    except ValueError:
                        format_errors.append(f"Line {line_num}: Invalid number format")
                
            if not lines or format_errors:
                if not lines:
                    logging.warning(f"File was empty: {label}")
                logging.warning(f"Removing invalid label file {label}:")
                for error in format_errors:
                    logging.warning(f"  {error}")
                os.remove(label_path)
            else:
                valid_labels.append(Path(label).stem)
                
        except Exception as e:
            logging.warning(f"Error processing label {label}: {e}")
            os.remove(label_path)


    # Ensure 1:1 pairing
    valid_pairs = set(valid_images) & set(valid_labels)
    orphaned_images = set(valid_images) - valid_pairs
    orphaned_labels = set(valid_labels) - valid_pairs
    
    # Remove orphaned files
    for orphan in orphaned_images:
        os.remove(os.path.join(images_path, f"{orphan}.jpg"))
    for orphan in orphaned_labels:
        os.remove(os.path.join(labels_path, f"{orphan}.txt"))
        
    # Log statistics
    logging.info(f"Dataset validation complete:")
    logging.info(f"- Valid image-label pairs: {len(valid_pairs)}")
    logging.info(f"- Removed images: {len(orphaned_images)}")
    logging.info(f"- Removed labels: {len(orphaned_labels)}")
    
    if not valid_pairs:
        logging.error("No valid image-label pairs found")
        raise ValueError("Empty dataset after validation")
        
    return images_path, labels_path
        


def create_dataset_structure(mode, repo_root):
    """Creates YOLO-compatible dataset directory structure.

    Generates standardized directory layout required by YOLO:
    ```
    dataset/
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ val/
    â”‚   â””â”€â”€ test/
    â””â”€â”€ labels/
        â”œâ”€â”€ train/
        â”œâ”€â”€ val/
        â””â”€â”€ test/
    ```

    Args:
        mode (str): Detection mode, either 'bricks' or 'studs'
        repo_root (Path): Repository root path for relative directory creation

    Returns:
        Path: Root path of created dataset structure

    Example:
        >>> repo_root = get_repo_root()
        >>> dataset_dir = create_dataset_structure('bricks', repo_root)
        >>> print(f"YOLO structure created at {dataset_dir}")

    Notes:
        - Creates cache/split/{mode} root directory
        - Sets up parallel image and label folders
        - Maintains train/val/test split organization
    """
    output_dir = repo_root / "cache" / "split" / f"{mode}"
    yolo_dirs = [
        output_dir / "dataset" / "images" / "train",
        output_dir / "dataset" / "images" / "val",
        output_dir / "dataset" / "images" / "test",
        output_dir / "dataset" / "labels" / "train",
        output_dir / "dataset" / "labels" / "val",
        output_dir / "dataset" / "labels" / "test"
    ]
    
    for yolo_dir in yolo_dirs:
        yolo_dir.mkdir(parents=True, exist_ok=True)
    logging.info(f"âœ… Dataset structure created at {output_dir}")
    return output_dir

def augment_data(dataset_path, augmentations=2):
    """Performs robust data augmentation on the training dataset.
    
    Applies a sequence of image augmentations while preserving YOLO annotation format:
    - Horizontal flips
    - Random brightness/contrast
    - Rotation (Â±15 degrees)
    - Gaussian blur
    - Color jitter

    Args:
        dataset_path (str): Path to the YOLO dataset root
        augmentations (int, optional): Number of augmented copies per image. Defaults to 2.

    Example:
        >>> augment_data('path/to/dataset', augmentations=3)
        >>> # Creates 3 augmented versions of each training image

    Warning:
        - Requires sufficient disk space (original_size * augmentations * 1.5)
        - Only augments training set images
        - Skips corrupted images while continuing processing

    Notes:
        - Uses Albumentations for efficient augmentation
        - Maintains YOLO bbox coordinates
        - Provides detailed progress tracking
        - Generates augmentation statistics
        - Implements robust error handling
    """
    
    # Setup paths and validation
    train_images_path = os.path.join(dataset_path, "dataset/images/train")
    train_labels_path = os.path.join(dataset_path, "dataset/labels/train")
    
    # Verify disk space
    free_space = shutil.disk_usage(train_images_path).free
    required_space = sum(os.path.getsize(os.path.join(train_images_path, f)) 
                        for f in os.listdir(train_images_path))
    if free_space < required_space * augmentations * 1.5:
        raise RuntimeError("Insufficient disk space for augmentation")
    
    # Configure augmentation pipeline with bbox support
    transform = A.Compose([
        A.HorizontalFlip(p=0.5),
        A.RandomBrightnessContrast(p=0.2),
        A.Rotate(limit=15, p=0.5),
        A.GaussianBlur(p=0.2),
        A.ColorJitter(p=0.2)
    ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))
    
    stats = {"processed": 0, "augmented": 0, "failed": 0}
    
    for img_file in os.listdir(train_images_path):
        if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
            continue
            
        try:
            # Load and validate image
            img_path = os.path.join(train_images_path, img_file)
            label_path = os.path.join(train_labels_path, 
                                    os.path.splitext(img_file)[0] + '.txt')
            
            image = cv2.imread(img_path)
            if image is None:
                raise ValueError(f"Failed to load image: {img_file}")
            
            # Load and validate labels
            bboxes = []
            class_labels = []
            if os.path.exists(label_path):
                with open(label_path, 'r') as f:
                    for line in f:
                        cls_id, x, y, w, h = map(float, line.strip().split())
                        bboxes.append([x, y, w, h])
                        class_labels.append(cls_id)
            
            # Perform augmentations
            for i in range(augmentations):
                try:
                    transformed = transform(image=image, bboxes=bboxes, 
                                         class_labels=class_labels)
                    
                    aug_image = transformed['image']
                    aug_bboxes = transformed['bboxes']
                    aug_labels = transformed['class_labels']
                    
                    # Save augmented image
                    aug_name = f"{os.path.splitext(img_file)[0]}_aug{i}{os.path.splitext(img_file)[1]}"
                    cv2.imwrite(os.path.join(train_images_path, aug_name), aug_image)
                    
                    # Save augmented labels
                    if bboxes:
                        label_name = f"{os.path.splitext(img_file)[0]}_aug{i}.txt"
                        with open(os.path.join(train_labels_path, label_name), 'w') as f:
                            for bbox, cls_id in zip(aug_bboxes, aug_labels):
                                f.write(f"{int(cls_id)} {' '.join(map(str, bbox))}\n")
                    
                    stats["augmented"] += 1
                    
                except Exception as e:
                    logging.error(f"Failed augmentation {i} for {img_file}: {str(e)}")
                    stats["failed"] += 1
                    continue
            
            stats["processed"] += 1
            
            # Log progress
            if stats["processed"] % 10 == 0:
                logging.info(f"Progress: {stats['processed']} images processed, "
                           f"{stats['augmented']} augmentations created, "
                           f"{stats['failed']} failures")
                
        except Exception as e:
            logging.error(f"Failed to process {img_file}: {str(e)}")
            stats["failed"] += 1
            continue
    
    # Final report
    logging.info("Augmentation Complete:")
    logging.info(f"  Images processed: {stats['processed']}")
    logging.info(f"  Augmentations created: {stats['augmented']}")
    logging.info(f"  Failed operations: {stats['failed']}")

def dataset_split(mode, repo_root):
    """
    Splits dataset into train (70%), val (20%), test (10%) and creates YOLO-compatible structure.
    
    Args:
        mode (str): 'bricks' or 'studs', defining dataset to split
        
    Returns:
        str: Path to the YOLO dataset directory
    """
    logging.info(f"Starting dataset split for {mode} mode")
    
    dataset_path = os.path.join(repo_root, "cache/datasets", mode)
    output_dir = os.path.join(repo_root, "cache/split", f"{mode}")

    subfolders = [f for f in os.listdir(dataset_path)
                  if os.path.isdir(os.path.join(dataset_path, f))]

    # Detect images and labels folders
    images_path = None
    labels_path = None
    
    for folder in subfolders:
        folder_path = os.path.join(dataset_path, folder)
        sample_files = os.listdir(folder_path)[:5]  # Check first 5 files
        
        # Check if folder contains images
        if any(f.lower().endswith(('.jpg', '.jpeg', '.png')) for f in sample_files):
            images_path = folder_path
        # Check if folder contains text files
        elif any(f.lower().endswith('.txt') for f in sample_files):
            labels_path = folder_path
    
    if not images_path or not labels_path:
        logging.error("Could not identify images and labels folders")
        raise ValueError("Invalid dataset structure")
        
    logging.info(f"Detected - Images: {images_path}, Labels: {labels_path}")
    
    logging.info(f"Source dataset: {dataset_path}")
    logging.info(f"Output directory: {output_dir}")

    image_files = sorted([f for f in os.listdir(images_path) if f.endswith(".jpg")])
    logging.info(f"Found {len(image_files)} images in dataset")
    
    random.shuffle(image_files)
    logging.info("Files randomly shuffled for unbiased split")

    num_train = int(len(image_files) * 0.7)
    num_val = int(len(image_files) * 0.2)

    train_files = image_files[:num_train]
    val_files = image_files[num_train:num_train + num_val]
    test_files = image_files[num_train + num_val:]
    
    logging.info(f"Split sizes: {len(train_files)} train, {len(val_files)} validation, {len(test_files)} test")

    # Ensure destination folders exist
    def ensure_folder_exists(path):
        os.makedirs(path, exist_ok=True)
        logging.debug(f"Ensured directory exists: {path}")

    logging.info("Creating YOLO directory structure")
    ensure_folder_exists(os.path.join(output_dir, "dataset/images/train"))
    ensure_folder_exists(os.path.join(output_dir, "dataset/images/val"))
    ensure_folder_exists(os.path.join(output_dir, "dataset/images/test"))
    ensure_folder_exists(os.path.join(output_dir, "dataset/labels/train"))
    ensure_folder_exists(os.path.join(output_dir, "dataset/labels/val"))
    ensure_folder_exists(os.path.join(output_dir, "dataset/labels/test"))

    def move_files(files, img_dst, lbl_dst):
        copied = 0
        missing_labels = 0
        for f in files:
            img_src = os.path.join(images_path, f)
            lbl_src = os.path.join(labels_path, f.replace(".jpg", ".txt"))
            
            # Copy image
            shutil.copy(img_src, os.path.join(output_dir, img_dst, f))
            
            # Check if label exists before copying
            if os.path.exists(lbl_src):
                shutil.copy(lbl_src, os.path.join(output_dir, lbl_dst, f.replace(".jpg", ".txt")))
                copied += 1
            else:
                missing_labels += 1
                logging.warning(f"Missing label for image {f}")
        
        logging.info(f"Copied {copied} image-label pairs to {img_dst}")
        if missing_labels > 0:
            logging.warning(f"Found {missing_labels} images without labels in {img_dst}")

    logging.info("Copying files to train split...")
    move_files(train_files, "dataset/images/train", "dataset/labels/train")
    
    logging.info("Copying files to validation split...")
    move_files(val_files, "dataset/images/val", "dataset/labels/val")
    
    logging.info("Copying files to test split...")
    move_files(test_files, "dataset/images/test", "dataset/labels/test")

    dataset_yaml = {
        "path": output_dir,
        "train": "dataset/images/train",
        "val": "dataset/images/val", 
        "test": "dataset/images/test",
        "nc": 1,
        "names": {
            0: "brick" if mode == "bricks" else "stud"
        }
    }

    yaml_path = os.path.join(output_dir, "dataset.yaml")
    with open(yaml_path, "w") as f:
        yaml.dump(dataset_yaml, f, default_flow_style=False)

    # empty the original dataset folder and log the completion
    shutil.rmtree(dataset_path)
    logging.info(f"âœ… Original dataset folder emptied: {dataset_path}")

    logging.info(f"âœ… Dataset split completed. Updated dataset.yaml at {yaml_path}")
    logging.info(f"Dataset ready for training with class: {dataset_yaml['names'][0]}")
    return output_dir

def split_dataset(mode, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):
    """
    Splits the dataset into training, validation, and test sets.

    Args:
        mode (str): 'bricks' or 'studs'.
        train_ratio (float): Proportion of the dataset to use for training.
        val_ratio (float): Proportion of the dataset to use for validation.
        test_ratio (float): Proportion of the dataset to use for testing.

    Returns:
        dict: Paths to the training, validation, and test sets.
    """
    repo_root = get_repo_root()
    dataset_path = os.path.join(repo_root, "cache/datasets", mode)
    images_path = os.path.join(dataset_path, "images")
    labels_path = os.path.join(dataset_path, "labels")

    image_files = sorted([f for f in os.listdir(images_path) if f.endswith(".jpg")])
    label_files = sorted([f for f in os.listdir(labels_path) if f.endswith(".txt")])

    # Ensure the dataset is valid
    if len(image_files) != len(label_files):
        logging.error("Mismatch between number of images and labels.")
        raise ValueError("Image-label count mismatch. Ensure every image has a corresponding label.")

    # Shuffle and split the dataset
    combined = list(zip(image_files, label_files))
    random.shuffle(combined)
    image_files[:], label_files[:] = zip(*combined)

    train_split = int(train_ratio * len(image_files))
    val_split = int((train_ratio + val_ratio) * len(image_files))

    train_images, val_images, test_images = image_files[:train_split], image_files[train_split:val_split], image_files[val_split:]
    train_labels, val_labels, test_labels = label_files[:train_split], label_files[train_split:val_split], label_files[val_split:]

    # Create directories for splits
    split_paths = {
        "train": {"images": os.path.join(images_path, "train"), "labels": os.path.join(labels_path, "train")},
        "val": {"images": os.path.join(images_path, "val"), "labels": os.path.join(labels_path, "val")},
        "test": {"images": os.path.join(images_path, "test"), "labels": os.path.join(labels_path, "test")}
    }

    for split in split_paths.values():
        os.makedirs(split["images"], exist_ok=True)
        os.makedirs(split["labels"], exist_ok=True)

    # Move files to respective directories
    for img, lbl in zip(train_images, train_labels):
        shutil.move(os.path.join(images_path, img), os.path.join(split_paths["train"]["images"], img))
        shutil.move(os.path.join(labels_path, lbl), os.path.join(split_paths["train"]["labels"], lbl))

    for img, lbl in zip(val_images, val_labels):
        shutil.move(os.path.join(images_path, img), os.path.join(split_paths["val"]["images"], img))
        shutil.move(os.path.join(labels_path, lbl), os.path.join(split_paths["val"]["labels"], lbl))

    for img, lbl in zip(test_images, test_labels):
        shutil.move(os.path.join(images_path, img), os.path.join(split_paths["test"]["images"], img))
        shutil.move(os.path.join(labels_path, lbl), os.path.join(split_paths["test"]["labels"], lbl))

    logging.info(f"âœ… Dataset split into train, val, and test sets for mode: {mode}")
    return split_paths

def display_dataset_info(mode):
    try:
        result = validate_dataset(mode)
        if result is None:
            # Fallback paths if validate_dataset returns None
            images_path = f"datasets/{mode}/images"
            labels_path = f"datasets/{mode}/labels"
            print(f"Warning: validate_dataset returned None. Using fallback paths.")
        else:
            images_path, labels_path = result
            
        # Rest of your existing function
        
        return images_path, labels_path
    except Exception as e:
        print(f"Error processing dataset info: {e}")
        # Return fallback values to avoid unpacking errors
        return f"datasets/{mode}/images", f"datasets/{mode}/labels"

# =============================================================================
# Training Functions
# =============================================================================

def select_model(mode, use_pretrained=False):
    """Selects appropriate YOLOv8 model for LEGO detection training.
    
    Provides smart model selection based on detection mode:
    - Can use pre-trained LEGO-specific models for transfer learning
    - Falls back to YOLOv8n for fresh training
    - Validates model file existence and accessibility

    Args:
        mode (str): Detection target ('bricks' or 'studs')
        use_pretrained (bool): Whether to use LEGO pre-trained weights

    Returns:
        str: Path to selected model weights file

    Example:
        >>> model_path = select_model('bricks', use_pretrained=True)
        >>> print(f"Selected model: {model_path}")

    Raises:
        FileNotFoundError: If requested pre-trained model is missing
    """
    repo_root = get_repo_root()
    
    if not use_pretrained:
        logging.info("âœ… Using default YOLOv8n model.")
        return "yolov8n.pt"
    
    model_dir = os.path.join(repo_root, "presentation/Models_DEMO")
    model_filename = "Brick_Model_best20250123_192838t.pt" if mode == "bricks" else "Stud_Model_best20250124_170824.pt"
    model_path = os.path.join(model_dir, model_filename)
    
    if os.path.exists(model_path):
        logging.info(f"âœ… Model selected: {model_path}")
        return model_path
    else:
        logging.error(f"âŒ Model not found at {model_path}")
        raise FileNotFoundError(f"Required model file is missing: {model_path}")

def save_model(model, output_dir, model_name="trained_model.pt"):
    """
    Saves the trained model to the specified directory.
    
    Args:
        model: YOLO model object to save
        output_dir (str): Directory to save the model
        model_name (str): Filename for the saved model
        
    Returns:
        str: Full path to the saved model file
    """
    model_save_path = os.path.join(output_dir, model_name)
    model.save(model_save_path)
    logging.info(f"âœ… Model saved to: {model_save_path}")
    return model_save_path

def train_model(dataset_path, model_path, device, epochs, batch_size, repo_root):
    """Trains YOLOv8 model for LEGO detection with robust error handling.

    Implements a complete training pipeline with:
    - Input validation and path checking
    - Automatic mode detection from dataset
    - Primary training via Python API
    - CLI-based fallback mechanism
    - Comprehensive logging and error capture
    - Results organization with timestamps

    Args:
        dataset_path (str): Path to YOLO dataset root
        model_path (str): Path to model file or YOLOv8 preset name
        device (str): Training device spec ("0", "cpu", etc.)
        epochs (int): Number of training epochs
        batch_size (int): Training batch size
        repo_root (str): Repository root path

    Returns:
        str: Path to training results directory

    Example:
        >>> results = train_model(
        ...     dataset_path='data/bricks',
        ...     model_path='yolov8n.pt',
        ...     device='0',
        ...     epochs=50,
        ...     batch_size=16,
        ...     repo_root=repo_path
        ... )
        >>> print(f"Training completed, results at: {results}")

    Notes:
        - Uses early stopping with patience=5
        - Enables single_cls for specialized detection
        - Creates timestamped results folders
        - Preserves both stdout and stderr logs
    """
    logging.info(f"ðŸš€ Starting training with model: {model_path}")
    
    # Validate inputs
    dataset_yaml_path = os.path.join(dataset_path, "dataset.yaml")

    # retrieve mode from yaml file
    with open(dataset_yaml_path, 'r') as f:
        dataset_config = yaml.safe_load(f)
        mode = dataset_config["names"][0]
        if mode == "lego_brick":
            mode = "bricks"
        elif mode == "lego_stud":
            mode = "studs"
        # log mode detected
        logging.info(f"Mode detected: {mode} ðŸ¯")

    if not os.path.exists(dataset_yaml_path):
        logging.error(f"âŒ Dataset YAML not found: {dataset_yaml_path}")
        raise FileNotFoundError(f"Dataset YAML file not found: {dataset_yaml_path}")
    
    # Verify dataset YAML content
    try:
        with open(dataset_yaml_path, 'r') as f:
            dataset_config = yaml.safe_load(f)
            logging.info(f"Dataset config: {dataset_config}")
            
            # Check required keys
            required_keys = ['path', 'train', 'val', 'test', 'nc', 'names']
            missing_keys = [key for key in required_keys if key not in dataset_config]
            if missing_keys:
                logging.error(f"âŒ Dataset YAML missing required keys: {missing_keys}")
                raise ValueError(f"Dataset YAML missing required keys: {missing_keys}")
            
            # Validate paths in the YAML
            for split in ['train', 'val', 'test']:
                split_path = os.path.join(dataset_path, dataset_config[split])
                if not os.path.exists(split_path):
                    logging.warning(f"âš ï¸ {split} path doesn't exist: {split_path}")
    except Exception as e:
        logging.error(f"âŒ Failed to validate dataset YAML: {e}")
        raise ValueError(f"Invalid dataset YAML: {e}")
    
    # Standard model presets don't need file existence check
    if not model_path.startswith("yolov8") and not os.path.exists(model_path):
        logging.error(f"âŒ Model file not found: {model_path}")
        raise FileNotFoundError(f"Model file not found: {model_path}")
    
    # Initialize model to verify it loads correctly
    try:
        model = YOLO(model_path)
        logging.info(f"âœ… Model initialized successfully: {model.task}, {model.names}")
    except Exception as e:
        logging.error(f"âŒ Failed to initialize model: {e}")
        raise RuntimeError(f"Failed to initialize YOLO model: {e}")
    
    # Setup training outputs
    training_name = f"training_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"
    results_dir = os.path.join(repo_root, f"results/{mode}")
    os.makedirs(results_dir, exist_ok=True)
    
    logging.info(f"Project path: {results_dir} âœ…")
    
    # Try Python API first as it's more reliable across platforms
    try:
        logging.info("Starting training through Python API...")
        results = model.train(
            data=dataset_yaml_path,
            epochs=epochs,
            batch=batch_size,
            device=device,
            project=results_dir,
            name=training_name,
            patience=5,
            single_cls=True,
            exist_ok=True,
            verbose=True # Use the detected mode as class name
        )
        logging.info("âœ… Training completed successfully via Python API.")
        return os.path.join(results_dir, training_name)
    except Exception as api_error:
        logging.warning(f"âš ï¸ Python API training failed: {api_error}. Attempting CLI method...")
        
        # Fall back to CLI method
        try:
            # Use normalized paths for CLI
            norm_model_path = os.path.normpath(model_path)
            norm_dataset_path = os.path.normpath(dataset_yaml_path)
            norm_results_dir = os.path.normpath(results_dir)
            
            command = [
                "yolo", 
                "task=detect",
                "train",
                f"model={norm_model_path}",
                f"data={norm_dataset_path}",
                f"epochs={epochs}",
                f"batch={batch_size}",
                f"device={device}",
                f"project={norm_results_dir}",
                f"name={training_name}",
                "patience=5",
                "single_cls=True",
                "exist_ok=True"
            ]
            
            logging.info(f"Executing command: {' '.join(command)}")
            
            # Capture and log both stdout and stderr
            process = subprocess.run(
                command, 
                check=False,
                text=True,
                capture_output=True
            )
            
            if process.returncode != 0:
                logging.error(f"âŒ CLI command failed with exit code {process.returncode}")
                logging.error(f"Command output: {process.stdout}")
                logging.error(f"Command error: {process.stderr}")
                raise RuntimeError(f"CLI training failed with exit code {process.returncode}. See logs for details.")
                
            logging.info("âœ… Training completed successfully via CLI.")
            return os.path.join(results_dir, training_name)
            
        except Exception as cli_error:
            logging.error(f"âŒ Training failed via both Python API and CLI: {cli_error}")
            raise RuntimeError(f"Training failed: Original error - {api_error}, CLI error - {cli_error}")

# =============================================================================
# Results Management
# =============================================================================

def zip_and_download_results(results_dir=None, output_filename=None):
    """Archives training results and provides download access.

    Creates a comprehensive training archive including:
    - Training metrics and plots
    - Model weights and configs
    - Log files and metadata
    - Validation image samples

    Args:
        results_dir (str, optional): Results directory to archive
        output_filename (str, optional): Name for ZIP archive

    Example:
        >>> zip_and_download_results('path/to/results')
        >>> # Creates downloadable ZIP with all training artifacts

    Notes:
        - Auto-detects results directory if not specified
        - Includes session logs from logs/ directory
        - Returns IPython FileLink for notebook downloads
        - Validates source paths and handles errors
    """
    if results_dir is None:
        results_dir = os.path.join(os.getcwd(), "results")
    if output_filename is None:
        output_filename = os.path.join(os.getcwd(), "..", "training_results.zip")

    # Convert Path object to string if needed
    if hasattr(output_filename, '__fspath__'):
        output_filename = str(output_filename)

    # First copy the logs folder to the results folder
    log_src = os.path.join(os.getcwd(), "logs")
    log_dst = os.path.join(results_dir, "logs")
    shutil.copytree(log_src, log_dst, dirs_exist_ok=True)   

    if not os.path.exists(results_dir):
        logging.error("âŒ No results folder found.")
        return

    # Create ZIP file using string paths
    base_filename = output_filename.replace(".zip", "")
    zip_path = shutil.make_archive(base_filename, 'zip', results_dir)
    
    logging.info(f"âœ… Training results compressed: {zip_path}")

    # Provide a direct download link
    display(FileLink(zip_path))

from rich.table import Table
from rich.console import Console
from rich.style import Style
import matplotlib.gridspec as gridspec
import numpy as np

def display_last_training_session(session_dir):
    """Visualizes training results with rich formatting and organization.
    
    Provides a comprehensive training results display:
    - Metric plots in organized grids
    - Training batch visualizations
    - CSV data in formatted tables
    - Configuration files with syntax highlighting

    Args:
        session_dir (str): Path to training session directory

    Example:
        >>> display_last_training_session('results/latest_training')
        >>> # Shows complete training visualization dashboard

    Notes:
        - Auto-scales plot grids based on file count
        - Uses Rich for terminal-based formatting
        - Implements parallel image loading
        - Handles missing or corrupt files gracefully
    """
    if not os.path.exists(session_dir):
        logging.error(f"Results directory not found: {session_dir}")
        return

    logging.info(f"Displaying training session: {session_dir}")
    files = sorted(os.listdir(session_dir))
    
    # Group files by type
    plot_files = [f for f in files if f.lower().endswith(('.jpg', '.png')) and 'batch' not in f]
    batch_files = [f for f in files if 'batch' in f.lower() and f.lower().endswith(('.jpg', '.png'))]
    csv_files = [f for f in files if f.lower().endswith('.csv')]
    text_files = [f for f in files if f.lower().endswith('.txt')]
    yaml_files = [f for f in files if f.lower().endswith('.yaml')]

    # Display plots in a grid
    if plot_files:
        n_plots = len(plot_files)
        n_cols = min(3, n_plots)
        n_rows = (n_plots + n_cols - 1) // n_cols
        
        fig = plt.figure(figsize=(15, 5*n_rows))
        gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
        
        for idx, file in enumerate(plot_files):
            file_path = os.path.join(session_dir, file)
            image = cv2.imread(file_path)
            if image is not None:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                ax = fig.add_subplot(gs[idx//n_cols, idx%n_cols])
                ax.imshow(image)
                ax.set_title(file)
                ax.axis('off')
        
        plt.tight_layout()
        display(fig)
        plt.close()

    # Display batch images in a grid
    if batch_files:
        n_batches = len(batch_files)
        n_cols = min(4, n_batches)
        n_rows = (n_batches + n_cols - 1) // n_cols
        
        fig = plt.figure(figsize=(15, 4*n_rows))
        gs = gridspec.GridSpec(n_rows, n_cols, figure=fig)
        
        for idx, file in enumerate(batch_files):
            file_path = os.path.join(session_dir, file)
            image = cv2.imread(file_path)
            if image is not None:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                ax = fig.add_subplot(gs[idx//n_cols, idx%n_cols])
                ax.imshow(image)
                ax.set_title(f"Batch {idx+1}")
                ax.axis('off')
        
        plt.suptitle("Training Batches", y=1.02, fontsize=16)
        plt.tight_layout()
        display(fig)
        plt.close()

    # Display CSV files with Rich formatting
    console = Console()
    for file in csv_files:
        file_path = os.path.join(session_dir, file)
        try:
            df = pd.read_csv(file_path)
            table = Table(title=f"\nðŸ“Š {file}", show_header=True, header_style="bold magenta")
            
            # Add columns
            for column in df.columns:
                table.add_column(column, justify="right", style="cyan")
            
            # Add rows with alternating colors
            for idx, row in df.iterrows():
                style = "dim" if idx % 2 == 0 else "none"
                table.add_row(*[str(val) for val in row], style=style)
            
            console.print(table)
            print("\n")  # Add spacing between tables
            
        except Exception as e:
            logging.error(f"Error reading CSV file {file}: {e}")

    # # Display text and YAML files
    # for file in text_files + yaml_files:
    #     file_path = os.path.join(session_dir, file)
    #     try:
    #         with open(file_path, 'r') as f:
    #             content = f.read()
    #             if file.lower().endswith('.yaml'):
    #                 content = yaml.safe_load(f)
    #             console.print(f"\nðŸ“„ {file}", style="bold blue")
    #             console.print("â”€" * 80)
    #             if isinstance(content, (dict, list)):
    #                 console.print(content, style="yellow")
    #             else:
    #                 console.print(content)
    #             console.print("â”€" * 80 + "\n")
    #     except Exception as e:
    #         logging.error(f"Error reading file {file}: {e}")