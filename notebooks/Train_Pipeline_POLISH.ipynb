{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ LEGO Bricks ML Vision - Training Pipeline\n",
                "\n",
                "## Environment-Agnostic Training Pipeline for YOLOv8 LEGO Detection Models\n",
                "\n",
                "This notebook provides a complete training pipeline that works seamlessly across:\n",
                "- üíª Local Windows development environment\n",
                "- ‚òÅÔ∏è Kaggle notebooks\n",
                "- üêß Linux/Unix systems\n",
                "\n",
                "### Key Features\n",
                "\n",
                "- **üîÑ Automatic Environment Detection**: Adapts to Windows/Kaggle/Linux\n",
                "- **üìÇ Smart Repository Management**: Auto-clones if needed\n",
                "- **üéØ Two-Stage Detection**: Trains both brick and stud detectors\n",
                "- **üìä Enhanced Visualization**: Rich progress tracking and results display\n",
                "- **üíæ Robust Data Handling**: Comprehensive dataset preparation and validation\n",
                "\n",
                "### Prerequisites\n",
                "- Python 3.8+\n",
                "- Git (for repository cloning)\n",
                "- Required packages will be automatically installed\n",
                "\n",
                "Let's begin by setting up our environment! üöÄ"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup and Validation\n",
                "\n",
                "First, we'll establish our execution environment and ensure all dependencies are in place."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import logging\n",
                "from pathlib import Path\n",
                "import subprocess\n",
                "import platform\n",
                "\n",
                "# Configure rich logging with emojis\n",
                "def setup_notebook_logging():\n",
                "    \"\"\"Configure rich logging with emoji support for better visibility.\"\"\"\n",
                "    logger = logging.getLogger(\"notebook_logger\")\n",
                "    if not logger.handlers:\n",
                "        handler = logging.StreamHandler()\n",
                "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
                "        handler.setFormatter(formatter)\n",
                "        logger.setLevel(logging.INFO)\n",
                "        logger.addHandler(handler)\n",
                "    return logger\n",
                "\n",
                "logger = setup_notebook_logging()\n",
                "\n",
                "def detect_environment():\n",
                "    \"\"\"Detect and validate execution environment.\"\"\"\n",
                "    env_info = {\n",
                "        'system': platform.system(),\n",
                "        'is_kaggle': 'KAGGLE_KERNEL_RUN_TYPE' in os.environ,\n",
                "        'python_version': platform.python_version(),\n",
                "        'git_available': shutil.which('git') is not None\n",
                "    }\n",
                "    \n",
                "    logger.info(f\"üîç Detected environment:\")\n",
                "    logger.info(f\"   ‚Ä¢ System: {env_info['system']}\")\n",
                "    logger.info(f\"   ‚Ä¢ Python: {env_info['python_version']}\")\n",
                "    logger.info(f\"   ‚Ä¢ Kaggle: {'Yes' if env_info['is_kaggle'] else 'No'}\")\n",
                "    logger.info(f\"   ‚Ä¢ Git: {'Available' if env_info['git_available'] else 'Not found'}\")\n",
                "    \n",
                "    return env_info\n",
                "\n",
                "def validate_repository_structure():\n",
                "    \"\"\"Validate or establish correct repository structure.\n",
                "    \n",
                "    1. Check if current directory is repo\n",
                "    2. Check if parent is repo\n",
                "    3. Check if grandparent is repo\n",
                "    4. Clone repo if not found\n",
                "    \"\"\"\n",
                "    REPO_NAME = \"LEGO_Bricks_ML_Vision\"\n",
                "    REPO_URL = \"https://github.com/MiguelDiLalla/LEGO_Bricks_ML_Vision.git\"\n",
                "    \n",
                "    cwd = Path.cwd()\n",
                "    parent = cwd.parent\n",
                "    grandparent = parent.parent\n",
                "    \n",
                "    # Check all possible locations\n",
                "    locations = [\n",
                "        (cwd, \"current directory\"),\n",
                "        (parent, \"parent directory\"),\n",
                "        (grandparent, \"grandparent directory\")\n",
                "    ]\n",
                "    \n",
                "    for path, desc in locations:\n",
                "        if path.name == REPO_NAME:\n",
                "            logger.info(f\"‚úÖ Repository found in {desc}: {path}\")\n",
                "            os.chdir(path)  # Set CWD to repo root\n",
                "            return path\n",
                "    \n",
                "    # Repository not found, need to clone\n",
                "    logger.info(f\"‚ö†Ô∏è Repository not found in directory tree. Cloning from GitHub...\")\n",
                "    try:\n",
                "        # Clone to current directory\n",
                "        subprocess.run([\"git\", \"clone\", REPO_URL], \n",
                "                     check=True, capture_output=True, text=True)\n",
                "        \n",
                "        repo_path = cwd / REPO_NAME\n",
                "        os.chdir(repo_path)  # Set CWD to new repo\n",
                "        logger.info(f\"‚úÖ Repository cloned successfully to: {repo_path}\")\n",
                "        return repo_path\n",
                "        \n",
                "    except subprocess.CalledProcessError as e:\n",
                "        logger.error(f\"‚ùå Failed to clone repository: {e.stderr}\")\n",
                "        raise\n",
                "\n",
                "# Execute environment setup\n",
                "env_info = detect_environment()\n",
                "repo_path = validate_repository_structure()\n",
                "\n",
                "# Add repository root to Python path\n",
                "if str(repo_path) not in sys.path:\n",
                "    sys.path.append(str(repo_path))\n",
                "    logger.info(f\"‚úÖ Added repository root to Python path\")\n",
                "\n",
                "logger.info(\"üéâ Environment setup complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "def install_requirements():\n",
                "    \"\"\"Install required packages from requirements.txt with progress tracking.\"\"\"\n",
                "    req_path = repo_path / \"requirements.txt\"\n",
                "    \n",
                "    if not req_path.exists():\n",
                "        logger.error(\"‚ùå requirements.txt not found!\")\n",
                "        return False\n",
                "    \n",
                "    try:\n",
                "        logger.info(\"üì¶ Installing required packages...\")\n",
                "        subprocess.run([\"pip\", \"install\", \"-r\", str(req_path), \"--quiet\"],\n",
                "                     check=True, capture_output=True)\n",
                "        logger.info(\"‚úÖ Package installation complete!\")\n",
                "        return True\n",
                "    except subprocess.CalledProcessError as e:\n",
                "        logger.error(f\"‚ùå Failed to install requirements: {e.stderr}\")\n",
                "        return False\n",
                "\n",
                "# Install requirements\n",
                "install_success = install_requirements()\n",
                "\n",
                "if install_success:\n",
                "    # Import project modules\n",
                "    from train import (\n",
                "        setup_logging, get_repo_root, detect_hardware,\n",
                "        unzip_dataset, validate_dataset, create_dataset_structure,\n",
                "        dataset_split, augment_data, select_model, train_model,\n",
                "        zip_and_download_results\n",
                "    )\n",
                "    \n",
                "    # Import required libraries\n",
                "    import torch\n",
                "    import cv2\n",
                "    import numpy as np\n",
                "    import matplotlib.pyplot as plt\n",
                "    from ultralytics import YOLO\n",
                "    import albumentations as A\n",
                "    from IPython.display import Image, display\n",
                "    \n",
                "    logger.info(\"‚úÖ All required modules imported successfully!\")\n",
                "else:\n",
                "    logger.error(\"‚ùå Failed to set up environment. Please check the errors above.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Hardware Detection and Training Setup\n",
                "\n",
                "Now we'll detect available hardware and configure our training environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize training environment\n",
                "setup_logging()  # Set up enhanced logging from train.py\n",
                "\n",
                "# Detect optimal hardware\n",
                "device = detect_hardware()\n",
                "logger.info(f\"üñ•Ô∏è Training will use device: {device}\")\n",
                "\n",
                "# Clean up any previous training sessions\n",
                "cleanup_training_sessions(repo_path)\n",
                "logger.info(\"üßπ Previous training sessions cleaned up\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Dataset Preparation\n",
                "\n",
                "Let's prepare our datasets for both brick and stud detection models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def prepare_datasets():\n",
                "    \"\"\"Prepare and validate both brick and stud detection datasets.\"\"\"\n",
                "    datasets = {}\n",
                "    \n",
                "    for mode in ['bricks', 'studs']:\n",
                "        logger.info(f\"\\n{'='*20} Preparing {mode} dataset {'='*20}\")\n",
                "        \n",
                "        # Extract dataset\n",
                "        dataset_path = unzip_dataset(mode)\n",
                "        \n",
                "        # Validate structure\n",
                "        images_path, labels_path = validate_dataset(mode)\n",
                "        \n",
                "        datasets[mode] = {\n",
                "            'path': dataset_path,\n",
                "            'images': images_path,\n",
                "            'labels': labels_path\n",
                "        }\n",
                "        \n",
                "        # Display statistics\n",
                "        image_count = len(list(Path(images_path).glob(\"*.jpg\")))\n",
                "        label_count = len(list(Path(labels_path).glob(\"*.txt\")))\n",
                "        logger.info(f\"üìä Dataset Statistics for {mode}:\")\n",
                "        logger.info(f\"   ‚Ä¢ Images: {image_count}\")\n",
                "        logger.info(f\"   ‚Ä¢ Labels: {label_count}\")\n",
                "    \n",
                "    return datasets\n",
                "\n",
                "# Prepare both datasets\n",
                "prepared_datasets = prepare_datasets()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.1 Dataset Visualization\n",
                "\n",
                "Let's visualize some samples from our datasets to verify annotations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_dataset_samples(datasets, num_samples=3):\n",
                "    \"\"\"Visualize sample images with annotations from both datasets.\n",
                "    \n",
                "    Args:\n",
                "        datasets (dict): Dictionary containing dataset paths\n",
                "        num_samples (int): Number of samples to display per dataset\n",
                "    \"\"\"\n",
                "    for mode, paths in datasets.items():\n",
                "        logger.info(f\"\\n{'='*20} {mode.capitalize()} Dataset Samples {'='*20}\")\n",
                "        \n",
                "        # Get random samples\n",
                "        image_files = list(Path(paths['images']).glob(\"*.jpg\"))\n",
                "        samples = random.sample(image_files, min(num_samples, len(image_files)))\n",
                "        \n",
                "        # Setup visualization\n",
                "        fig, axes = plt.subplots(1, len(samples), figsize=(5*len(samples), 5))\n",
                "        if len(samples) == 1:\n",
                "            axes = [axes]\n",
                "        \n",
                "        # Define visualization colors\n",
                "        colors = {\n",
                "            'bricks': {'box': 'red', 'text': 'white', 'bg': 'darkred'},\n",
                "            'studs': {'box': 'blue', 'text': 'white', 'bg': 'darkblue'}\n",
                "        }\n",
                "        \n",
                "        for idx, (img_path, ax) in enumerate(zip(samples, axes)):\n",
                "            # Load and display image\n",
                "            img = cv2.imread(str(img_path))\n",
                "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "            ax.imshow(img)\n",
                "            \n",
                "            # Load and display annotations\n",
                "            label_path = Path(paths['labels']) / f\"{img_path.stem}.txt\"\n",
                "            if label_path.exists():\n",
                "                with open(label_path) as f:\n",
                "                    for line in f:\n",
                "                        cls_id, x, y, w, h = map(float, line.strip().split())\n",
                "                        \n",
                "                        # Convert YOLO coordinates to pixel coordinates\n",
                "                        height, width = img.shape[:2]\n",
                "                        x1 = int((x - w/2) * width)\n",
                "                        y1 = int((y - h/2) * height)\n",
                "                        x2 = int((x + w/2) * width)\n",
                "                        y2 = int((y + h/2) * height)\n",
                "                        \n",
                "                        # Draw bounding box\n",
                "                        rect = plt.Rectangle(\n",
                "                            (x1, y1), x2-x1, y2-y1,\n",
                "                            fill=False,\n",
                "                            edgecolor=colors[mode]['box'],\n",
                "                            linewidth=2\n",
                "                        )\n",
                "                        ax.add_patch(rect)\n",
                "                        \n",
                "                        # Add label\n",
                "                        ax.text(\n",
                "                            x1, y1-5,\n",
                "                            f\"{mode[:-1].capitalize()} {int(cls_id)}\",\n",
                "                            color=colors[mode]['text'],\n",
                "                            bbox=dict(\n",
                "                                facecolor=colors[mode]['bg'],\n",
                "                                alpha=0.8,\n",
                "                                edgecolor='none',\n",
                "                                pad=1\n",
                "                            )\n",
                "                        )\n",
                "            \n",
                "            ax.set_title(f\"{mode.capitalize()} Sample {idx+1}\")\n",
                "            ax.axis('off')\n",
                "        \n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "\n",
                "# Visualize samples from both datasets\n",
                "visualize_dataset_samples(prepared_datasets)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Dataset Splitting and Augmentation\n",
                "\n",
                "Now we'll split our datasets into train/val/test sets and apply augmentation to increase model robustness."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_datasets(datasets):\n",
                "    \"\"\"Split datasets and apply augmentation to training sets.\n",
                "    \n",
                "    Args:\n",
                "        datasets (dict): Dictionary containing dataset paths\n",
                "    \n",
                "    Returns:\n",
                "        dict: Processed dataset paths\n",
                "    \"\"\"\n",
                "    processed_datasets = {}\n",
                "    \n",
                "    for mode, paths in datasets.items():\n",
                "        logger.info(f\"\\n{'='*20} Processing {mode} dataset {'='*20}\")\n",
                "        \n",
                "        # Create YOLO directory structure\n",
                "        dataset_dir = create_dataset_structure(mode, repo_path)\n",
                "        \n",
                "        # Split dataset\n",
                "        split_paths = dataset_split(mode, repo_path)\n",
                "        \n",
                "        # Apply augmentation to training set\n",
                "        logger.info(f\"üîÑ Applying augmentation to {mode} training set...\")\n",
                "        augment_data(dataset_dir, augmentations=2)\n",
                "        \n",
                "        processed_datasets[mode] = dataset_dir\n",
                "        \n",
                "    return processed_datasets\n",
                "\n",
                "# Process both datasets\n",
                "processed_datasets = process_datasets(prepared_datasets)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Training\n",
                "\n",
                "### 4.1 Training Configuration\n",
                "\n",
                "Let's set up our training parameters and initialize our models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def configure_training(mode):\n",
                "    \"\"\"Configure training parameters for a specific mode.\n",
                "    \n",
                "    Args:\n",
                "        mode (str): Either 'bricks' or 'studs'\n",
                "        \n",
                "    Returns:\n",
                "        dict: Training configuration parameters\n",
                "    \"\"\"\n",
                "    config = {\n",
                "        'epochs': 50,\n",
                "        'batch_size': 16,\n",
                "        'device': device,\n",
                "        'use_pretrained': True\n",
                "    }\n",
                "    \n",
                "    # Select appropriate model\n",
                "    model_path = select_model(mode, use_pretrained=config['use_pretrained'])\n",
                "    config['model_path'] = model_path\n",
                "    \n",
                "    logger.info(f\"‚öôÔ∏è Training configuration for {mode}:\")\n",
                "    for key, value in config.items():\n",
                "        logger.info(f\"   ‚Ä¢ {key}: {value}\")\n",
                "    \n",
                "    return config\n",
                "\n",
                "# Configure training for both modes\n",
                "training_configs = {\n",
                "    mode: configure_training(mode)\n",
                "    for mode in ['bricks', 'studs']\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 Model Training\n",
                "\n",
                "Now we'll train both the brick and stud detection models with progress tracking."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_models(processed_datasets, training_configs):\n",
                "    \"\"\"Train models for both brick and stud detection.\n",
                "    \n",
                "    Args:\n",
                "        processed_datasets (dict): Paths to processed datasets\n",
                "        training_configs (dict): Training configurations\n",
                "        \n",
                "    Returns:\n",
                "        dict: Paths to training results\n",
                "    \"\"\"\n",
                "    training_results = {}\n",
                "    \n",
                "    for mode in ['bricks', 'studs']:\n",
                "        logger.info(f\"\\n{'='*20} Training {mode} detector {'='*20}\")\n",
                "        \n",
                "        config = training_configs[mode]\n",
                "        dataset_dir = processed_datasets[mode]\n",
                "        \n",
                "        # Train model\n",
                "        results_dir = train_model(\n",
                "            dataset_path=dataset_dir,\n",
                "            model_path=config['model_path'],\n",
                "            device=config['device'],\n",
                "            epochs=config['epochs'],\n",
                "            batch_size=config['batch_size'],\n",
                "            repo_root=repo_path\n",
                "        )\n",
                "        \n",
                "        training_results[mode] = results_dir\n",
                "        logger.info(f\"‚úÖ {mode} model training completed!\")\n",
                "    \n",
                "    return training_results\n",
                "\n",
                "# Train both models\n",
                "training_results = train_models(processed_datasets, training_configs)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Results Export and Visualization\n",
                "\n",
                "Finally, let's save our training results and visualize the model performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def export_training_results(training_results):\n",
                "    \"\"\"Export and archive training results for both models.\n",
                "    \n",
                "    Args:\n",
                "        training_results (dict): Paths to training results directories\n",
                "    \"\"\"\n",
                "    for mode, results_dir in training_results.items():\n",
                "        logger.info(f\"\\n{'='*20} Exporting {mode} results {'='*20}\")\n",
                "        \n",
                "        # Create timestamped filename\n",
                "        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
                "        output_filename = f\"{mode}_training_results_{timestamp}.zip\"\n",
                "        \n",
                "        # Zip and provide download link\n",
                "        zip_and_download_results(results_dir, output_filename)\n",
                "        logger.info(f\"‚úÖ {mode} results exported successfully!\")\n",
                "\n",
                "# Export results for both models\n",
                "export_training_results(training_results)\n",
                "\n",
                "logger.info(\"\\nüéâ Training pipeline completed successfully! üéâ\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Training Results Analysis\n",
                "\n",
                "Let's analyze the training results and visualize model performance metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from train import display_last_training_session\n",
                "\n",
                "# Display results for both models\n",
                "for mode, results_dir in training_results.items():\n",
                "    print(f\"\\n{'='*40}\")\n",
                "    print(f\"Results Analysis for {mode.upper()} Detection Model\")\n",
                "    print(f\"{'='*40}\\n\")\n",
                "    display_last_training_session(results_dir)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "MiguelEnv310",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
