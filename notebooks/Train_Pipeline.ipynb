{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEGO Bricks ML Vision - Training Pipeline Demonstration\n",
    "\n",
    "This notebook provides a step-by-step demonstration of training the YOLO-based computer vision models for detecting LEGO bricks and studs. The training pipeline showcases how to:\n",
    "\n",
    "1. Prepare and process LEGO brick/stud datasets\n",
    "2. Configure and train YOLOv8 models \n",
    "3. Evaluate model performance\n",
    "4. Export models for inference\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "The LEGO Bricks ML Vision project uses two distinct computer vision models:\n",
    "- **Brick Detection Model**: Identifies complete LEGO bricks in images\n",
    "- **Stud Detection Model**: Identifies individual studs on LEGO bricks\n",
    "\n",
    "Together, these models enable the full classification pipeline that can identify brick dimensions based on stud patterns.\n",
    "\n",
    "![Training Pipeline Overview](../docs/assets/images/train_pipeline_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for \"LEGO_BRICKS_ML_VISION\" folder in the cwd folder branch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import logging\n",
    "import rich.logging as rlog\n",
    "\n",
    "# Set up rich logger with emoji support\n",
    "logger = logging.getLogger(\"notebook_logger\")\n",
    "if not logger.handlers:\n",
    "    handler = rlog.RichHandler(rich_tracebacks=True, markup=True, show_time=False)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "    logger.info(\"✅ [bold green]Logger initialized for LEGO ML Vision notebook[/bold green]\")\n",
    "\n",
    "def check_repo_clone():\n",
    "    \"\"\"\n",
    "    Check if the cwd name matches the repo name.\n",
    "    If not, check if the parent folder matches the repo name.\n",
    "    If not, clone the repo.\n",
    "\n",
    "    Returns the local repo root path and adds it to the sys.path\n",
    "    \"\"\"\n",
    "    # Set up rich logger\n",
    "    logger = logging.getLogger(\"repo_setup\")\n",
    "    handler = rlog.RichHandler(rich_tracebacks=True, markup=True)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    if not logger.handlers:\n",
    "        logger.addHandler(handler)\n",
    "    \n",
    "    userGithub = \"MiguelDiLalla\"\n",
    "    repoGithub = \"LEGO_Bricks_ML_Vision\"\n",
    "    repo_url = f\"https://github.com/{userGithub}/{repoGithub}.git\"\n",
    "\n",
    "    cwd = Path.cwd()\n",
    "    cwd_name = cwd.name\n",
    "    cwd_parent = cwd.parent\n",
    "\n",
    "    logger.info(f\"Checking for repository: [bold blue]{repoGithub}[/bold blue]\")\n",
    "    \n",
    "    if cwd_name != repoGithub and cwd_parent.name != repoGithub:\n",
    "        logger.info(f\"Repository not found in current path or parent directory\")\n",
    "        logger.info(f\"Cloning from [green]{repo_url}[/green]...\")\n",
    "        \n",
    "        try:\n",
    "            subprocess.run([\"git\", \"clone\", repo_url], check=True)\n",
    "            logger.info(f\"Repository successfully cloned\")\n",
    "            # Add the repo to the sys.path\n",
    "            sys.path.append(cwd / repoGithub)\n",
    "            # Change the cwd to the repo root\n",
    "            os.chdir(cwd / repoGithub)\n",
    "            return cwd / repoGithub\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            logger.error(f\"Failed to clone repository: {e}\")\n",
    "            logger.error(f\"Please clone manually with: git clone {repo_url}\")\n",
    "            raise RuntimeError(f\"Repository setup failed: {e}\")\n",
    "    else:\n",
    "        repo_path = cwd if cwd_name == repoGithub else cwd_parent\n",
    "        logger.info(f\"Repository [bold blue]{repoGithub}[/bold blue] already available at [bold green]{repo_path}[/bold green]\")\n",
    "        \n",
    "        # Add the repo to the sys.path\n",
    "        sys.path.append(repo_path)\n",
    "        # Change the cwd to the repo root (and log it)\n",
    "        logger.info(f\"Changing working directory to: [bold green]{repo_path}[/bold green]\")\n",
    "        os.chdir(repo_path)\n",
    "        return repo_path\n",
    "\n",
    "repo_clone_path = check_repo_clone()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def setup_requirements(repo_path):\n",
    "    \"\"\"\n",
    "    Fetch the requirements.txt file\n",
    "    check if the requirements are already installed\n",
    "    install the requirements if not installed\n",
    "\n",
    "    returns none and sumary the installed and missing packages\n",
    "    \"\"\"\n",
    "    # Set up rich logger\n",
    "    logger = logging.getLogger(\"requirements_setup\")\n",
    "    handler = rlog.RichHandler(rich_tracebacks=True, markup=True)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    if not logger.handlers:\n",
    "        logger.addHandler(handler)\n",
    "\n",
    "    requirements_path = repo_path / \"requirements.txt\"\n",
    "    logger.info(f\"Checking for requirements file: [bold blue]{requirements_path}[/bold blue]\")\n",
    "\n",
    "    if requirements_path.exists():\n",
    "        logger.info(f\"Requirements file found\")\n",
    "        with open(requirements_path, \"r\") as f:\n",
    "            requirements = f.read().splitlines()\n",
    "        logger.info(f\"Checking for installed packages...\")\n",
    "        installed_packages = subprocess.run([\"pip\", \"freeze\"], capture_output=True, text=True).stdout.splitlines()\n",
    "        missing_packages = [pkg for pkg in requirements if not any(pkg.split(\"==\")[0] in pkg for pkg in installed_packages)]\n",
    "        if missing_packages:\n",
    "            logger.info(f\"Missing packages: [bold red]{missing_packages}[/bold red]\")\n",
    "            logger.info(f\"Installing missing packages...\")\n",
    "            subprocess.run([\"pip\", \"install\", *missing_packages], check=True)\n",
    "            logger.info(f\"Requirements successfully installed\")\n",
    "        else:\n",
    "            logger.info(f\"All requirements are already installed\")\n",
    "    else:\n",
    "        logger.error(f\"Requirements file not found\")\n",
    "        logger.error(f\"Please create a requirements.txt file with the required packages\")\n",
    "        raise FileNotFoundError(f\"Requirements file not found: {requirements_path}\")\n",
    "\n",
    "setup_requirements(repo_clone_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from IPython.display import Image, display\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image as PILImage\n",
    "import random\n",
    "\n",
    "\n",
    "# Import project modules\n",
    "from train import setup_logging, detect_hardware, load_config, cleanup_training_sessions\n",
    "from train import unzip_dataset, validate_dataset, create_dataset_structure, dataset_split , augment_data\n",
    "from train import select_model, train_model, display_last_training_session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Setup logging and load configuration\n",
    "setup_logging()\n",
    "config = load_config()\n",
    "\n",
    "# Detect optimal hardware\n",
    "device = detect_hardware()\n",
    "print(f\"Training will use device: {device}\")\n",
    "\n",
    "cleanup_training_sessions(repo_clone_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Exploration\n",
    "\n",
    "Let's examine our dataset before training. We have separate datasets for brick detection and stud detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Extract and prepare datasets\n",
    "brick_dataset_path = unzip_dataset(\"bricks\")\n",
    "stud_dataset_path = unzip_dataset(\"studs\")\n",
    "\n",
    "# Display dataset information\n",
    "def display_dataset_info(mode):\n",
    "    images_path, labels_path = validate_dataset(mode)\n",
    "    image_count = len(list(Path(images_path).glob(\"*.jpg\")))\n",
    "    label_count = len(list(Path(labels_path).glob(\"*.txt\")))\n",
    "    \n",
    "    print(f\"\\n{mode.capitalize()} Dataset:\")\n",
    "    print(f\"- Images path: {images_path}\")\n",
    "    print(f\"- Labels path: {labels_path}\")\n",
    "    print(f\"- Total images: {image_count}\")\n",
    "    print(f\"- Total labels: {label_count}\")\n",
    "    \n",
    "    if image_count != label_count:\n",
    "        print(f\"⚠️  Warning: Number of images and labels do not match\")\n",
    "        raise ValueError(\"Number of images and labels do not match\")\n",
    "    \n",
    "    return images_path, labels_path\n",
    "\n",
    "bricks_images_path, bricks_labels_path = display_dataset_info(\"bricks\")\n",
    "studs_images_path, studs_labels_path = display_dataset_info(\"studs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Sample Images with Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_sample_with_annotations(images_path, labels_path, mode, num_samples=3):\n",
    "    \"\"\"\n",
    "    Visualize sample images with their YOLO format annotations.\n",
    "    \n",
    "    Args:\n",
    "        images_path: Path to images directory\n",
    "        labels_path: Path to labels directory \n",
    "        mode: Either \"bricks\" or \"studs\" to determine visualization style\n",
    "        num_samples: Number of samples to visualize\n",
    "    \"\"\"\n",
    "    # Get image files and ensure we don't exceed available samples\n",
    "    image_files = list(Path(images_path).glob(\"*.jpg\"))\n",
    "    num_samples = min(num_samples, len(image_files))\n",
    "    samples = random.sample(image_files, num_samples)\n",
    "    \n",
    "    # Create figure for horizontal layout\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(5*num_samples, 5))\n",
    "    if num_samples == 1:\n",
    "        axes = [axes]  # Make iterable for single sample case\n",
    "        \n",
    "    # Define colors based on mode\n",
    "    colors = {\n",
    "        \"bricks\": {\"box\": \"red\", \"text_bg\": \"darkred\"},\n",
    "        \"studs\": {\"box\": \"blue\", \"text_bg\": \"darkblue\"}\n",
    "    }\n",
    "    color = colors.get(mode, {\"box\": \"green\", \"text_bg\": \"darkgreen\"})\n",
    "    \n",
    "    for i, (img_path, ax) in enumerate(zip(samples, axes)):\n",
    "        # Load image\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        height, width = img.shape[:2]\n",
    "        \n",
    "        # Display image\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"{mode.capitalize()} Sample {i+1}\\n{img_path.name}\", fontsize=10)\n",
    "        ax.axis('off')  # Hide axis for cleaner visualization\n",
    "        \n",
    "        # Try to find the corresponding label file\n",
    "        label_file = Path(labels_path) / f\"{img_path.stem}.txt\"\n",
    "        \n",
    "        # If not found directly, check subdirectories\n",
    "        if not label_file.exists():\n",
    "            parent_dir = Path(labels_path).parent\n",
    "            for subdir in ['train', 'val', 'test']:\n",
    "                alt_path = parent_dir / subdir / \"labels\" / f\"{img_path.stem}.txt\"\n",
    "                if alt_path.exists():\n",
    "                    label_file = alt_path\n",
    "                    break\n",
    "        \n",
    "        # Load and draw annotations if label file exists\n",
    "        if label_file.exists():\n",
    "            with open(label_file, 'r') as f:\n",
    "                annotations = f.readlines()\n",
    "            \n",
    "            # Process each annotation\n",
    "            for ann in annotations:\n",
    "                parts = ann.strip().split()\n",
    "                if len(parts) >= 5:  # Ensure valid YOLO format\n",
    "                    class_id = int(float(parts[0]))\n",
    "                    x_center, y_center, w, h = map(float, parts[1:5])\n",
    "                    \n",
    "                    # Convert normalized YOLO coordinates to pixel values\n",
    "                    x1 = int((x_center - w/2) * width)\n",
    "                    y1 = int((y_center - h/2) * height)\n",
    "                    x2 = int((x_center + w/2) * width)\n",
    "                    y2 = int((y_center + h/2) * height)\n",
    "                    \n",
    "                    # Draw bounding box\n",
    "                    rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                                        fill=False, edgecolor=color[\"box\"], linewidth=2)\n",
    "                    ax.add_patch(rect)\n",
    "                    \n",
    "                    # Add label text with background\n",
    "                    ax.text(x1, y1-5, f\"Class {class_id}\", color='white', fontsize=8,\n",
    "                           bbox=dict(facecolor=color[\"text_bg\"], alpha=0.7))\n",
    "        else:\n",
    "            ax.text(10, 30, \"No labels found\", color='white', fontsize=10,\n",
    "                   bbox=dict(facecolor='red', alpha=0.7))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display dataset samples with annotations\n",
    "print(\"\\n===== Brick Detection Dataset Samples =====\")\n",
    "visualize_sample_with_annotations(bricks_images_path, bricks_labels_path, \"bricks\")\n",
    "\n",
    "print(\"\\n===== Stud Detection Dataset Samples =====\")\n",
    "visualize_sample_with_annotations(studs_images_path, studs_labels_path, \"studs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create YOLO training structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {},
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dataset_structure(\"bricks\", repo_clone_path)\n",
    "create_dataset_structure(\"studs\", repo_clone_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train, validation, and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "bricks_split_path = dataset_split(\"bricks\", repo_clone_path)\n",
    "studs_split_path = dataset_split(\"studs\", repo_clone_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment Training Data using Albumentations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "augment_data(bricks_split_path, 2)\n",
    "augment_data(studs_split_path, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the Brick Detection Model\n",
    "\n",
    "Now let's train the YOLOv8 model for brick detection. We'll use the training pipeline from `train.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Training configuration for the brick detection model\n",
    "brick_training_params = {\n",
    "    \"dataset_path\": bricks_split_path,\n",
    "    \"model_path\": select_model(\"bricks\", use_pretrained=False),\n",
    "    \"device\": device,\n",
    "    \"epochs\": 1,\n",
    "    \"batch_size\": 2,\n",
    "    \"repo_root\": repo_clone_path\n",
    "}\n",
    "\n",
    "print(\"Starting Brick Detection Model Training...\")\n",
    "print(f\"Parameters: {brick_training_params}\")\n",
    "\n",
    "# Run the training pipeline (set to shorter epochs for demo purposes)\n",
    "try:\n",
    "    brick_results_dir = train_model(**brick_training_params)\n",
    "    print(f\"\\nTraining completed. Results saved to: {brick_results_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"Training error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Brick Detection Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display training session output files:\n",
    "\n",
    "#   get the directory of the training session by last time modified\n",
    "\n",
    "brick_results_dir = Path(repo_clone_path) / \"results\" / \"bricks\"\n",
    "last_bricks_results_dir = max(brick_results_dir.glob(\"*\"), key=lambda f: f.stat().st_mtime)\n",
    "\n",
    "display_last_training_session(last_bricks_results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the Stud Detection Model\n",
    "\n",
    "Now we'll train the YOLOv8 model for detecting studs on LEGO bricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Training configuration for the stud detection model\n",
    "studs_training_params = {\n",
    "    \"dataset_path\": studs_split_path,\n",
    "    \"model_path\": select_model(\"bricks\", use_pretrained=False),\n",
    "    \"device\": device,\n",
    "    \"epochs\": 1,\n",
    "    \"batch_size\": 2,\n",
    "    \"repo_root\": repo_clone_path\n",
    "}\n",
    "\n",
    "print(\"Starting Studs Detection Model Training...\")\n",
    "print(f\"Parameters: {studs_training_params}\")\n",
    "\n",
    "# Run the training pipeline (set to shorter epochs for demo purposes)\n",
    "try:\n",
    "    studs_results_dir = train_model(**studs_training_params)\n",
    "    print(f\"\\nTraining completed. Results saved to: {studs_results_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"Training error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Stud Detection Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Display training session output files:\n",
    "\n",
    "#   get the directory of the training session by last time modified\n",
    "\n",
    "studs_results_dir = Path(repo_clone_path) / \"results\" / \"studs\"\n",
    "last_studs_results_dir = max(studs_results_dir.glob(\"*\"), key=lambda f: f.stat().st_mtime)\n",
    "\n",
    "display_last_training_session(last_studs_results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation on Test Images\n",
    "\n",
    "Let's test our trained models on some unseen images to see how they perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Load the best trained models\n",
    "try:\n",
    "    brick_model_path = Path(last_bricks_results_dir) / \"weights\" / \"best.pt\"\n",
    "    stud_model_path = Path(last_studs_results_dir) / \"weights\" / \"best.pt\"\n",
    "    \n",
    "    brick_model = YOLO(str(brick_model_path))\n",
    "    stud_model = YOLO(str(stud_model_path))\n",
    "    \n",
    "    print(f\"Models loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Inference modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core detection utilities\n",
    "from utils.detection_utils import detect_bricks, detect_studs\n",
    "\n",
    "# Visualization utilities\n",
    "from utils.visualization_utils import draw_detection_visualization\n",
    "\n",
    "# Configuration (needed for model loading)\n",
    "from utils.config_utils import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set images avaible inside the presentation folder \n",
    "\n",
    "Bricks_Presentation_folder = Path(repo_clone_path) / \"presentation\" / \"Test_images\" / \"BricksPics\"\n",
    "Studs_Presentation_folder = Path(repo_clone_path) / \"presentation\" / \"Test_images\" / \"StudsPics\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Brick Detection Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 6 images from the Bricks folder\n",
    "brick_images = list(Bricks_Presentation_folder.glob(\"*.jpg\"))\n",
    "selected_images = random.sample(brick_images, min(6, len(brick_images)))\n",
    "\n",
    "# Create a figure with 2x3 grid\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Process each image and display results\n",
    "for idx, image_path in enumerate(selected_images):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    \n",
    "    # Run brick detection\n",
    "    brick_results = detect_bricks(\n",
    "        str(image_path),\n",
    "        conf=0.25,\n",
    "        save_annotated=False\n",
    "    )\n",
    "    \n",
    "    # Load and display the annotated image\n",
    "    img = PILImage.open(image_path)\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Draw detections\n",
    "    annotated_img = draw_detection_visualization(img, brick_results)\n",
    "    \n",
    "    # Display in grid\n",
    "    axes[row, col].imshow(annotated_img)\n",
    "    axes[row, col].set_title(f'Brick Detection: {image_path.name}')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Stud Detection Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 6 images from the Studs folder\n",
    "stud_images = list(Studs_Presentation_folder.glob(\"*.jpg\"))\n",
    "selected_images = random.sample(stud_images, min(6, len(stud_images)))\n",
    "\n",
    "# Create a figure with 2x3 grid\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Process each image and display results\n",
    "for idx, image_path in enumerate(selected_images):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    \n",
    "    # Run stud detection\n",
    "    stud_results = detect_studs(\n",
    "        str(image_path),\n",
    "        conf=0.25,\n",
    "        save_annotated=False\n",
    "    )\n",
    "    \n",
    "    # Load and display the annotated image\n",
    "    img = PILImage.open(image_path)\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Draw detections\n",
    "    annotated_img = draw_detection_visualization(img, stud_results)\n",
    "    \n",
    "    # Display in grid\n",
    "    axes[row, col].imshow(annotated_img)\n",
    "    axes[row, col].set_title(f'Stud Detection: {image_path.name}')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MiguelEnv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
